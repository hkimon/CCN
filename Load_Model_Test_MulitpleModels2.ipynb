{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8d2f52",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Core\n",
    "# =============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# =============================\n",
    "# Plotting\n",
    "# =============================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Optional: if you actually use these\n",
    "# import matplotlib.cm as cm\n",
    "# import seaborn as sns\n",
    "\n",
    "# =============================\n",
    "# TensorFlow / Keras  (use tf.keras only)\n",
    "# =============================\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose,\n",
    "    BatchNormalization, Dropout, Flatten, Reshape, Concatenate, Add,\n",
    "    Activation, LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# =============================\n",
    "# Sklearn\n",
    "# =============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# =============================\n",
    "# Stats / Metrics\n",
    "# =============================\n",
    "from scipy.stats import pearsonr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "# =============================\n",
    "# Jupyter widgets\n",
    "# =============================\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "\n",
    "# =============================\n",
    "# Datashader (only if used)\n",
    "# =============================\n",
    "# import datashader as ds\n",
    "# from datashader.mpl_ext import dsshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cd0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Training data\n",
    "# =============================\n",
    "\n",
    "with h5py.File(\"TrainData.mat\", \"r\") as f:\n",
    "    y_train = f[\"lvSaveDataInput\"][:, :, :, :]\n",
    "    x_train = f[\"lvLovalizerSave\"][:, :, :, :]\n",
    "\n",
    "# Move channel axis (1 → last)\n",
    "x_train = np.moveaxis(x_train, 1, -1)\n",
    "y_train = np.moveaxis(y_train, 1, -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# important for model building later on\n",
    "input_shape  = x_train.shape[1:]   \n",
    "output_shape = y_train.shape[1:]      \n",
    "\n",
    "print(\"Input shape:\", input_shape)\n",
    "print(\"Output shape:\", output_shape)\n",
    "\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2236c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Validation data\n",
    "# =============================\n",
    "\n",
    "with h5py.File(\"ValData.mat\", \"r\") as f:\n",
    "    y_val = f[\"lvSaveDataInput\"][:, :, :, :]\n",
    "    x_val = f[\"lvLovalizerSave\"][:, :, :, :]\n",
    "\n",
    "# Move channel axis (1 → last)\n",
    "x_val = np.moveaxis(x_val, 1, -1)\n",
    "y_val = np.moveaxis(y_val, 1, -1)\n",
    "\n",
    "print(\"x_val shape:\", x_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b513b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc4e690",
   "metadata": {},
   "source": [
    "# Double Convolutional Block 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97361cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def C2D_BLock(x, n_filters, kernel_size=3, batchnorm=True):\n",
    "    x = Conv2D(n_filters, (kernel_size, kernel_size), padding=\"same\", kernel_initializer=init)(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    # LeakyReLU uses a small slope (alpha) for x < 0 instead of zeroing negatives\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    " \n",
    "\n",
    "    x = Conv2D(n_filters, (kernel_size, kernel_size), padding=\"same\", kernel_initializer=init)(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    # LeakyReLU uses a small slope (alpha) for x < 0 instead of zeroing negatives\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6965e",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img, convolution_type, iterations, n_filters, dropout, batchnorm):\n",
    "    \"\"\"Simple encoder with configurable iterations.\"\"\"\n",
    "    features = []\n",
    "    x = input_img\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Convolution block\n",
    "        down = convolution_type(x, n_filters=n_filters*(2**i), kernel_size=3, batchnorm=batchnorm)\n",
    "        features.append(down)\n",
    "        \n",
    "        # Max pooling (except for last iteration - that's the bottleneck)\n",
    "        if i < iterations - 1:\n",
    "            x = MaxPooling2D((2, 2))(down)\n",
    "            # Dropout with increasing rate for deeper layers\n",
    "            dropout_rate = dropout * (2 if i >= 2 else 1)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "        else:\n",
    "            # Bottleneck dropout\n",
    "            x = Dropout(dropout * 3)(down)\n",
    "            features[-1] = x  # Update last feature with dropout\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe306591",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38591ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(bottleneck, skip_connections, convolution_type, transpose_conv_type, iterations, n_filters, dropout, batchnorm, heads=8):\n",
    "    \"\"\"Simple decoder with multiple heads.\"\"\"\n",
    "    outputs = []\n",
    "    \n",
    "    for head in range(heads):\n",
    "        x = bottleneck\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            # Calculate filter size (decreasing: 8, 4, 2, 1)\n",
    "            current_filters = n_filters * (2 ** (iterations - i - 1))\n",
    "            \n",
    "            # Upsampling with configurable transpose convolution\n",
    "            x = transpose_conv_type(current_filters, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "            x = concatenate([x, skip_connections[i]])\n",
    "            \n",
    "            # Dropout (higher rate for first 2 iterations)\n",
    "            dropout_rate = dropout * (2 if i < 2 else 1)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "            \n",
    "            # Convolution block\n",
    "            x = convolution_type(x, n_filters=current_filters, kernel_size=3, batchnorm=batchnorm)\n",
    "        \n",
    "        # Output layer\n",
    "        output = Conv2D(2, (1, 1), activation='tanh', name=f\"outputsCh{head+1}\")(x)\n",
    "        outputs.append(output)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d224c",
   "metadata": {},
   "source": [
    "# U Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6178a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_unet2D(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    \n",
    "    # --- Single-slice encoder (no multi-slice fusion) ---\n",
    "    features = encoder(\n",
    "        input_img=input_img,\n",
    "        convolution_type=C2D_BLock,\n",
    "        iterations=5,\n",
    "        n_filters=n_filters,\n",
    "        dropout=dropout,\n",
    "        batchnorm=batchnorm,\n",
    "    )\n",
    "    \n",
    "    # Unpack encoder features\n",
    "    down1, down2, down3, down4, down5 = features   # normal UNet skip connections\n",
    "    \n",
    "    # --- Decoder with 8 heads ---\n",
    "    outputs = decoder(\n",
    "        bottleneck=down5,\n",
    "        skip_connections=[down4, down3, down2, down1],\n",
    "        convolution_type=C2D_BLock,\n",
    "        transpose_conv_type=Conv2DTranspose,\n",
    "        iterations=4,\n",
    "        n_filters=n_filters,\n",
    "        dropout=dropout,\n",
    "        batchnorm=batchnorm,\n",
    "        heads=8,\n",
    "    )\n",
    "    \n",
    "    model = Model(inputs=[input_img], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06577dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73e2acaa",
   "metadata": {},
   "source": [
    "# Initialize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(input_shape)\n",
    "model = define_unet2D(input_img, n_filters=32, dropout=0.001, batchnorm=False)\n",
    "model.load_weights(\"weights.h5\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63f07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6de68313",
   "metadata": {},
   "source": [
    "# Load model weights & training history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f41ac8",
   "metadata": {},
   "source": [
    "# Site A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc18e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_site_a = model.load_weights('.h5')\n",
    "history_site_a = np.load('.npy',allow_pickle='TRUE').item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e93473",
   "metadata": {},
   "source": [
    "# Load Testing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adda89a",
   "metadata": {},
   "source": [
    "# Site A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6abf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Testing data Site A\n",
    "# =============================\n",
    "\n",
    "with h5py.File(\"TestDataSiteA.mat\", \"r\") as f:\n",
    "    y_test_site_a = f[\"lvSaveDataInput\"][:, :, :, :]\n",
    "    x_test_site_a = f[\"lvLovalizerSave\"][:, :, :, :]\n",
    "\n",
    "# Move channel axis (1 → last)\n",
    "x_test_site_a = np.moveaxis(x_test_site_a, 1, -1)\n",
    "y_test_site_a = np.moveaxis(y_test_site_a, 1, -1)\n",
    "\n",
    "print(\"x_test_site_a shape:\", x_test_site_a.shape)\n",
    "print(\"y_test_site_a shape:\", y_test_site_a.shape)\n",
    "\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Ground-truth B1+ maps (complex-valued)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Reconstruct complex-valued ground truth from real/imag pairs\n",
    "b1p_groundtruth_complex_site_a = y_val[..., 0::2] + 1j * y_val[..., 1::2]\n",
    "\n",
    "# or load from saved file\n",
    "# b1p_groundtruth_complex_site_a = np.load(\"b1p_gt_complex_site_a.npy\") \n",
    "\n",
    "# Derived representations (channel-first for convenience)\n",
    "b1p_gt_magnitude_site_a = np.moveaxis(np.abs(b1p_groundtruth_complex_site_a),   -1, 0)\n",
    "b1p_gt_phase_site_a     = np.moveaxis(np.angle(b1p_groundtruth_complex_site_a), -1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a93402",
   "metadata": {},
   "source": [
    "# Inference on unseen test data Site A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5059450",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_site_a = np.array(model.predict(x_test_site_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Predicted B1+ maps (complex-valued)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Reconstruct complex-valued prediction from real/imag pairs\n",
    "\n",
    "b1p_prediction_complex_site_a = prediction_site_a[..., 0] + 1j * prediction_site_a[..., 1]\n",
    "# or load from saved file\n",
    "# b1p_prediction_complex_site_a = np.load(\"b1p_pr_complex_site_a.npy\") \n",
    "\n",
    "\n",
    "# Derived representations (channel-first for convenience)\n",
    "b1p_pr_magnitude_site_a = np.abs(b1p_prediction_complex_site_a)\n",
    "b1p_pr_phase_site_a     = np.angle(b1p_prediction_complex_site_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc9003",
   "metadata": {},
   "source": [
    "# Apply Mask Site A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbf530",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('.mat', 'r') as f:\n",
    "    mask_site_a = f[\"mask\"][:, :, :]   \n",
    "\n",
    "# =============================\n",
    "# Expand mask to 8 Tx channels\n",
    "# =============================\n",
    "\n",
    "mask_site_a = np.tile(mask_site_a, [8, 1, 1, 1])\n",
    "\n",
    "# =============================\n",
    "# Apply mask \n",
    "# =============================\n",
    "\n",
    "# Ground truth: \n",
    "b1p_gt_magnitude_site_a_masked   = b1p_gt_magnitude_site_a * mask_site_a\n",
    "b1p_gt_phase_site_a_masked       = b1p_gt_phase_site_a * mask_site_a\n",
    "\n",
    "# Prediction: \n",
    "b1p_pr_magnitude_site_a_masked   = b1p_pr_magnitude_site_a   * mask_site_a\n",
    "b1p_pr_phase_site_a_masked       = b1p_pr_phase_site_a * mask_site_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e9c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f5046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c764e62f",
   "metadata": {},
   "source": [
    "# Site B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Testing data Site B\n",
    "# =============================\n",
    "\n",
    "with h5py.File(\"TestDataSiteB.mat\", \"r\") as f:\n",
    "    y_test_site_b = f[\"lvSaveDataInput\"][:, :, :, :]\n",
    "    x_test_site_b = f[\"lvLovalizerSave\"][:, :, :, :]\n",
    "\n",
    "# Move channel axis (1 → last)\n",
    "x_test_site_b = np.moveaxis(x_test_site_b, 1, -1)\n",
    "y_test_site_b = np.moveaxis(y_test_site_b, 1, -1)\n",
    "\n",
    "print(\"x_test_site_b shape:\", x_test_site_b.shape)\n",
    "print(\"y_test_site_b shape:\", y_test_site_b.shape)\n",
    "\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Ground-truth B1+ maps (complex-valued)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Reconstruct complex-valued ground truth from real/imag pairs\n",
    "b1p_groundtruth_complex_site_b = y_test_site_b[..., 0::2] + 1j * y_test_site_b[..., 1::2]\n",
    "\n",
    "# or load from saved file\n",
    "\n",
    "# Derived representations (channel-first for convenience)\n",
    "b1p_gt_magnitude_site_b = np.moveaxis(np.abs(b1p_groundtruth_complex_site_b),   -1, 0)\n",
    "b1p_gt_phase_site_b    = np.moveaxis(np.angle(b1p_groundtruth_complex_site_b), -1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d15d38",
   "metadata": {},
   "source": [
    "# Inference on unseen test data Site B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_site_b = np.array(model.predict(x_test_site_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Predicted B1+ maps (complex-valued)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Reconstruct complex-valued prediction from real/imag pairs\n",
    "\n",
    "b1p_prediction_complex_site_b = prediction_site_b[..., 0] + 1j * prediction_site_b[..., 1]\n",
    "# or load from saved file\n",
    "\n",
    "\n",
    "# Derived representations (channel-first for convenience)\n",
    "b1p_pr_magnitude_site_b = np.abs(b1p_prediction_complex_site_b)\n",
    "b1p_pr_phase_site_b     = np.angle(b1p_prediction_complex_site_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d7bf8",
   "metadata": {},
   "source": [
    "# Apply Mask Site B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('.mat', 'r') as f:\n",
    "    mask_site_b = f[\"mask\"][:, :, :]   \n",
    "\n",
    "# =============================\n",
    "# Expand mask to 8 Tx channels\n",
    "# =============================\n",
    "\n",
    "mask_site_b = np.tile(mask_site_b, [8, 1, 1, 1])\n",
    "\n",
    "# =============================\n",
    "# Apply mask \n",
    "# =============================\n",
    "\n",
    "# Ground truth: \n",
    "b1p_gt_magnitude_site_b_masked   = b1p_gt_magnitude_site_b * mask_site_b\n",
    "b1p_gt_phase_site_b_masked       = b1p_gt_phase_site_b * mask_site_b\n",
    "\n",
    "# Prediction: \n",
    "b1p_pr_magnitude_site_b_masked   = b1p_pr_magnitude_site_b   * mask_site_b\n",
    "b1p_pr_phase_site_b_masked       = b1p_pr_phase_site_b * mask_site_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bcb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b560bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83ffdbb6",
   "metadata": {},
   "source": [
    "# Simple Plot Comaprison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1db953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b1p_est_gt_diff(\n",
    "    b1p_est_complex,\n",
    "    b1p_gt_complex,\n",
    "    slice_idx,\n",
    "    vmin_mag=0.0,\n",
    "    vmax_mag=0.25,\n",
    "    vmax_diff=0.10,\n",
    "):\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # Figure layout\n",
    "    # ------------------------------------------------------------\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(14, 8))\n",
    "    fig.suptitle(fr\"$B_1^+$ Magnitude – Slice {slice_idx}\", fontsize=14)\n",
    "\n",
    "    # Column titles (Tx channels)\n",
    "    for ch in range(8):\n",
    "        axes[0, ch].set_title(f\"Ch {ch + 1}\", fontsize=10)\n",
    "\n",
    "    # Row labels\n",
    "    row_labels = [\"EST\", \"GT\", \"|EST − GT|\"]\n",
    "    for r, label in enumerate(row_labels):\n",
    "        axes[r, 0].annotate(\n",
    "            label,\n",
    "            xy=(-0.35, 0.5),\n",
    "            xycoords=\"axes fraction\",\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            rotation=90,\n",
    "            fontsize=11,\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot per channel\n",
    "    # ------------------------------------------------------------\n",
    "    for ch in range(8):\n",
    "        mag_est = np.abs(b1p_est_complex[ch, slice_idx])\n",
    "        mag_gt  = np.abs(b1p_gt_complex[ch, slice_idx])\n",
    "        mag_df  = np.abs(mag_est - mag_gt)\n",
    "\n",
    "        # Mask background / noise floor\n",
    "        mag_est = np.where(mag_est < 0.01, np.nan, mag_est)\n",
    "        mag_gt  = np.where(mag_gt  < 0.01, np.nan, mag_gt)\n",
    "        mag_df  = np.where(mag_df  < 0.01, np.nan, mag_df)\n",
    "\n",
    "        axes[0, ch].imshow(\n",
    "            mag_est.T, cmap=\"plasma\", vmin=vmin_mag, vmax=vmax_mag\n",
    "        )\n",
    "        axes[1, ch].imshow(\n",
    "            mag_gt.T,  cmap=\"plasma\", vmin=vmin_mag, vmax=vmax_mag\n",
    "        )\n",
    "        axes[2, ch].imshow(\n",
    "            mag_df.T,  cmap=\"inferno\", vmin=0.0, vmax=vmax_diff\n",
    "        )\n",
    "\n",
    "        for r in range(3):\n",
    "            axes[r, ch].axis(\"off\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Shared colorbar (magnitude)\n",
    "    # ------------------------------------------------------------\n",
    "    cbar_ax = fig.add_axes([0.1, 0.05, 0.8, 0.02])\n",
    "    cbar = fig.colorbar(\n",
    "        axes[0, 0].images[0], cax=cbar_ax, orientation=\"horizontal\"\n",
    "    )\n",
    "    cbar.set_label(\"B1⁺ magnitude (a.u.)\", fontsize=10)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left=0.03, right=0.98, top=0.88, bottom=0.12,\n",
    "        wspace=0.0, hspace=0.0\n",
    "    )\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_b1p_est_gt_diff(b1p_pr_magnitude_site_a_masked,b1p_gt_magnitude_site_a_masked, slice_idx=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_b1p_est_gt_diff(b1p_pr_magnitude_site_b_masked,b1p_gt_magnitude_site_b_masked, slice_idx=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
